{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14759809f5464d14bb2e9e7770b48a6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for TFIDF:\n",
      "               travel         telephone      government     slate          fiction        \n",
      "fiction        20.09%         19.39%         19.19%         20.28%         21.05%         \n",
      "telephone      0%             100.0%         0%             0%             0%             \n",
      "travel         50.0%          25.0%          0%             25.0%          0%             \n",
      "telephone      0%             93.9%          2.44%          2.44%          1.22%          \n",
      "telephone      0%             100.0%         0%             0%             0%"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext \n",
    "from pyspark.ml.feature import HashingTF,IDF,Tokenizer\n",
    "from pyspark.sql import SQLContext\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from pyspark.ml.clustering import KMeans,KMeansModel\n",
    "from pyspark.sql.types import ArrayType, DoubleType\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def deleteFirstRow(record):\n",
    "    try:\n",
    "        index, promptID, pairID, genre, sentence1_binary_parse, sentence2_binary_parse, \\\n",
    "        sentence1_parse, sentence2_parse, sentence1, sentence2, label1, label2, label3, \\\n",
    "        label4, label5, gold_label = record.split(\"\\t\")\n",
    "        if(index == \"index\"):\n",
    "        \treturn False\n",
    "        else:\n",
    "        \treturn True\n",
    "    except:\n",
    "        try:\n",
    "            index, promptID, pairID, genre, sentence1_binary_parse, \\\n",
    "    \t\tsentence2_binary_parse, sentence1_parse, sentence2_parse, sentence1, \\\n",
    "    \t\tsentence2 = record.split(\"\\t\")\n",
    "            if(index == \"index\"):\n",
    "                return False\n",
    "            else:\n",
    "                return True\n",
    "        except:\n",
    "            try:\n",
    "                index, promptID, pairID, genre, sentence1_binary_parse, \\\n",
    "                sentence2_binary_parse, sentence1_parse, sentence2_parse, sentence1, \\\n",
    "                sentence2, label1, gold_label = record.split(\"\\t\")\n",
    "                if(index == \"index\"):\n",
    "                    return False\n",
    "                else:\n",
    "                    return True\n",
    "            except:\n",
    "                return ()\n",
    "                \n",
    "def extractGenreAndSentencesForFlatmap(record):\n",
    "    try:\n",
    "        index, promptID, pairID, genre, sentence1_binary_parse, sentence2_binary_parse, \\\n",
    "        sentence1_parse, sentence2_parse, sentence1, sentence2, label1, \\\n",
    "        gold_label = record.split(\"\\t\")\n",
    "        genre_sentences = [(genre, sentence1), (genre, sentence2)]\n",
    "        return (genre_sentences)\n",
    "    except:\n",
    "        return()\n",
    "    \n",
    "def emb(record):\n",
    "    url = \"https://tfhub.dev/google/universal-sentence-encoder/2\"\n",
    "    embed = hub.Module(url)\n",
    "    data = [row for row in record]\n",
    "    sentence_list = [row[1] for row in data]\n",
    "    with tf.Session() as session:\n",
    "        session.run([tf.global_variables_initializer(), tf.tables_initializer()])\n",
    "        embeddings = session.run(embed(sentence_list))\n",
    "    return [(data[i][0], embeddings[i]) for i in range(len(data))]\n",
    "\n",
    "def toPrint(result):\n",
    "    sum_list = [0,0,0,0,0]\n",
    "    genres = []\n",
    "    for item in result:\n",
    "        predict, genre, count = item\n",
    "        sum_list[predict] += count\n",
    "        if genre not in genres:\n",
    "            genres.append(genre)\n",
    "\n",
    "    cluster = {}\n",
    "    for item in result:\n",
    "        predict, genre, count = item\n",
    "        index = genres.index(genre)\n",
    "        if predict not in cluster.keys():\n",
    "            cluster[predict] = [0]*5\n",
    "        cluster[predict][index] = count/sum_list[predict]*100\n",
    "    print('{:15s}'.format(\"\"), end = \"\")\n",
    "    for g in genres:\n",
    "        print('{:15s}'.format(g), end = \"\")\n",
    "    print()\n",
    "    i=0\n",
    "    while i<len(cluster):\n",
    "        pos = cluster[i].index(max(cluster[i]))\n",
    "        print('{:15s}'.format(genres[pos]), end = \"\")\n",
    "        for p in cluster[i]:\n",
    "            print('{:15s}'.format(str(round(p,2)) + \"%\"), end = \"\")\n",
    "        i+=1\n",
    "        print()\n",
    "        \n",
    "def toList(record):\n",
    "    genre, features = record\n",
    "    return(genre, features.tolist())\n",
    "\n",
    "input_file_train = 's3://comp5349-slia7223/e-4AT2I9YSEAYUVL0BCTAB2KP5Y/train.tsv'\n",
    "\n",
    "spark_conf = SparkConf().setAppName(\"Comp 5349 Assignment 2 Sentence Vector Exploaration\")\n",
    "sc=SparkContext.getOrCreate(spark_conf) \n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "text_train = sc.textFile(input_file_train)\n",
    "\n",
    "pure_text_train = text_train.filter(deleteFirstRow)\n",
    "genre_and_sentences_after_flatmap = pure_text_train.flatMap(extractGenreAndSentencesForFlatmap)\n",
    "genre_and_sentences_after_flatmap.persist()\n",
    "\n",
    "# TFIDF\n",
    "tfidf_dataFrame = genre_and_sentences_after_flatmap.toDF([\"genre\",\"sentence\"])\n",
    "tokenizer = Tokenizer(inputCol=\"sentence\", outputCol=\"words\")\n",
    "tfidf_words_data = tokenizer.transform(tfidf_dataFrame)\n",
    "\n",
    "hashing_tf = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\", numFeatures=512)\n",
    "tfidf_featurized_data = hashing_tf.transform(tfidf_words_data)\n",
    "\n",
    "idf_model = IDF(inputCol=\"rawFeatures\", outputCol=\"features\").fit(tfidf_featurized_data)\n",
    "tfidf_rescaled_data = idf_model.transform(tfidf_featurized_data)\n",
    "tfidf_genre_features = tfidf_rescaled_data.select(\"genre\", \"features\")\n",
    "\n",
    "# Confusion matrix for TFIDF\n",
    "tfidf_kmeansmodel = KMeans().setK(5).setFeaturesCol('features').setPredictionCol('prediction').fit(tfidf_genre_features)\n",
    "tfidf_predictions = tfidf_kmeansmodel.transform(tfidf_genre_features).select(\"prediction\", \"genre\")\n",
    "tfidf_res = tfidf_predictions.groupBy(['prediction', 'genre']).count().collect()\n",
    "print(\"Confusion matrix for TFIDF:\")\n",
    "toPrint(tfidf_res)\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28ab88ff2464268987d4a086f14efb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dd"
     ]
    }
   ],
   "source": [
    "print(\"dd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e924df24755e49158023776b602abd5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for pretrained:\n",
      "               travel         telephone      fiction        government     slate          \n",
      "fiction        3.09%          30.67%         46.65%         3.87%          15.72%         \n",
      "travel         62.97%         21.84%         5.38%          3.48%          6.33%          \n",
      "slate          29.21%         12.37%         11.0%          3.44%          43.99%         \n",
      "government     3.09%          15.72%         0.77%          62.89%         17.53%         \n",
      "telephone      2.97%          36.8%          36.06%         8.18%          15.99%         \n",
      "PythonRDD[562] at RDD at PythonRDD.scala:53"
     ]
    }
   ],
   "source": [
    "# pretrained\n",
    "pretrained_genre_features = genre_and_sentences_after_flatmap.mapPartitions(emb)\n",
    "pretrained_dataFrame = pretrained_genre_features.map(toList).toDF([\"genre\",\"features\"])\n",
    "\n",
    "new_schema = ArrayType(DoubleType(), containsNull=False)\n",
    "udf_foo = udf(lambda x:x, new_schema)\n",
    "pretrained_dataFrame = pretrained_dataFrame.withColumn(\"features\",udf_foo(\"features\"))\n",
    "\n",
    "# Confusion matrix for pretrained\n",
    "pretrained_kmeansmodel = KMeans().setK(5).setFeaturesCol('features').setPredictionCol('prediction').fit(pretrained_dataFrame)\n",
    "pretrained_predictions = pretrained_kmeansmodel.transform(pretrained_dataFrame).select(\"prediction\", \"genre\")\n",
    "pretrained_res = pretrained_predictions.groupBy(['prediction', 'genre']).count().collect()\n",
    "print(\"Confusion matrix for pretrained:\")\n",
    "toPrint(pretrained_res)\n",
    "\n",
    "genre_and_sentences_after_flatmap.unpersist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark",
   "language": "",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 2
   },
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
